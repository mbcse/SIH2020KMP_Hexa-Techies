{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "from io import BytesIO\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import pdf2image\n",
    "import os\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jpg(file_name,csv_output_file):\n",
    "    table_csv = get_table_csv_results(file_name)\n",
    "    with open(csv_output_file, \"w\") as fout:\n",
    "        fout.write(table_csv)\n",
    "    \n",
    "    #print('CSV OUTPUT FILE: ',csv_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(file_name,csv_output_file):    \n",
    "    from pdf2image import convert_from_path\n",
    "    pages = convert_from_path(file_name, 500)\n",
    "    table_csv=\"\"\n",
    "    for page in pages:\n",
    "        page.save('out.jpeg', 'JPEG')\n",
    "        table_csv+= get_table_csv_results('out.jpeg')\n",
    "        os.remove(\"out.jpeg\")\n",
    "         \n",
    "    with open(csv_output_file, \"w\") as fout:\n",
    "        fout.write(table_csv)\n",
    "        \n",
    "    print('CSV OUTPUT FILE: ',csv_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_columns_map(table_result, blocks_map):\n",
    "    rows = {}\n",
    "    for relationship in table_result['Relationships']:\n",
    "        if relationship['Type'] == 'CHILD':\n",
    "            for child_id in relationship['Ids']:\n",
    "                cell = blocks_map[child_id]\n",
    "                if cell['BlockType'] == 'CELL':\n",
    "                    row_index = cell['RowIndex']\n",
    "                    col_index = cell['ColumnIndex']\n",
    "                    if row_index not in rows:\n",
    "                        # create new row\n",
    "                        rows[row_index] = {}\n",
    "                        \n",
    "                    # get the text value\n",
    "                    rows[row_index][col_index] = get_text(cell, blocks_map)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def get_text(result, blocks_map):\n",
    "    text = ''\n",
    "    if 'Relationships' in result:\n",
    "        for relationship in result['Relationships']:\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                for child_id in relationship['Ids']:\n",
    "                    word = blocks_map[child_id]\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        text += word['Text'] + ' '\n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] =='SELECTED':\n",
    "                            text +=  'X '    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_table_csv_results(file_name):\n",
    "\n",
    "    with open(file_name, 'rb') as file:\n",
    "        img_test = file.read()\n",
    "        bytes_test = bytearray(img_test)\n",
    "        #print('Image loaded', file_name)\n",
    "\n",
    "    # process using image bytes\n",
    "    # get the results\n",
    "    client = boto3.client('textract')\n",
    "\n",
    "    response = client.analyze_document(Document={'Bytes': bytes_test}, FeatureTypes=['TABLES'])\n",
    "\n",
    "    # Get the text blocks\n",
    "    blocks=response['Blocks']\n",
    "    #pprint(blocks)\n",
    "\n",
    "    blocks_map = {}\n",
    "    table_blocks = []\n",
    "    for block in blocks:\n",
    "        blocks_map[block['Id']] = block\n",
    "        if block['BlockType'] == \"TABLE\":\n",
    "            table_blocks.append(block)\n",
    "\n",
    "    if len(table_blocks) <= 0:\n",
    "        return \"<b> NO Table FOUND </b>\"\n",
    "\n",
    "    csv = ''\n",
    "    for index, table in enumerate(table_blocks):\n",
    "        csv += generate_table_csv(table, blocks_map, index +1)\n",
    "        csv += '\\n\\n'\n",
    "\n",
    "    return csv\n",
    "\n",
    "def generate_table_csv(table_result, blocks_map, table_index):\n",
    "    rows = get_rows_columns_map(table_result, blocks_map)\n",
    "\n",
    "    table_id = 'Table_' + str(table_index)\n",
    "    \n",
    "    # get cells.\n",
    "    csv = 'Table: {0}\\n\\n'.format(table_id)\n",
    "\n",
    "    for row_index, cols in rows.items():\n",
    "        \n",
    "        for col_index, text in cols.items():\n",
    "            csv += '{}'.format(text) + \",\"\n",
    "        csv += '\\n'\n",
    "        \n",
    "    csv += '\\n\\n\\n'\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_json(file_name,json_output_file):\n",
    "    file_name= csv_output_file\n",
    "    rows=[]\n",
    "    with open(file_name, 'r',encoding=\"utf8\") as csvfile:        \n",
    "        csvreader = csv.reader(csvfile) \n",
    "\n",
    "        # extracting field names through first row \n",
    "        fields = next(csvreader) \n",
    "\n",
    "        # extracting each data row one by one \n",
    "        for row in csvreader: \n",
    "            rows.append(row) \n",
    "            \n",
    "    #removing empty lines\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(len(rows)):  \n",
    "        #print(\"rows:\",rows[i])\n",
    "        if(len(rows[i])>=2):\n",
    "            temp = []\n",
    "            for j in range(len(rows[i])):\n",
    "                if(len(rows[i][j])>1):\n",
    "                    temp.append(rows[i][j].strip())\n",
    "            #print(\"temp:\",temp)\n",
    "            temp_list.append(temp)\n",
    "    \n",
    "    master_list = []\n",
    "    for i in range(len(temp_list)):\n",
    "        if len(temp_list[i])>=2:\n",
    "            master_list.append(temp_list[i])\n",
    "\n",
    "\n",
    "    \n",
    "    master_dict = {}\n",
    "    for i in range(len(master_list)):  \n",
    "\n",
    "        value = master_list[i][1]\n",
    "        try:\n",
    "            for j in master_list[i][2:]:\n",
    "                value+= \",\" + j\n",
    "            master_dict[master_list[i][0]] = value\n",
    "        except:\n",
    "            master_dict[master_list[i][0]] = value\n",
    "    \n",
    "    \n",
    "    json_object = json.dumps(master_dict, indent = 4) \n",
    "    json_final = json.loads(json_object)\n",
    "    with open(json_output_file,'w') as outfile:\n",
    "        json.dump(json_final, outfile)\n",
    "        \n",
    "    #print(json_object)    \n",
    "    return json_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_file_name(file_path):\n",
    "    # This function has been created to get the actaul name of the file\n",
    "    # i.e irrespective of any file extensions(.pdf/.jpg etc.) and path extensions(//.../../)\n",
    "    # E.G: from asdf//dsfdsf/xyz.pdf it will return xyz only \n",
    "    \n",
    "    #CAUTION : VERY NOOB CODE :P\n",
    "    \n",
    "    #removing the extension \n",
    "    file_path = file_path[::-1]\n",
    "    file_less_ext = file_path[file_path.index('.')+1:][::-1]\n",
    "    \n",
    "    #print(file_less_ext)\n",
    "    \n",
    "    #removing the path to get the actual name\n",
    "    try:\n",
    "        index = file_less_ext[::-1].index(\"/\")    \n",
    "        #path_index = file_less_ext[::-1].index(\"/\")        \n",
    "        temp_less_path = file_less_ext[::-1]        \n",
    "        temp_less_path=temp_less_path[:temp_less_path.index('/')]\n",
    "        final_name = temp_less_path[::-1]\n",
    "        \n",
    "    except:\n",
    "        final_name = file_less_ext\n",
    "        \n",
    "    return final_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV OUTPUT FILE:  Aerodrome_and_Site_Clearance_Form.csv\n",
      "{'Aerodrome and Site Clearance': 'Form', 'Name of the applicant': 'Sudhanshu Chaudhary', 'Full Address': 'Anmol Ratan Building,3rd Floor', 'Te No./Fax No.': '9876543210', 'Permanent E-Mail Address': 'Sudhanshu@indianair.com', 'Name of the Directors/ Partners/Promoters': 'None', 'Nature of the applicant firm or company': 'Public Limited Company', 'Location of Aerodrame': 'Greater Noida', 'Name of nearest civilian airport': 'IGI', 'Nearest Civilain airport distance from proposed airport': '84.2 kms', 'Tota Land Area identified': '2200acres', 'Ownership of Land': 'Governmnet,Agriculture', 'Forest land': 'None', 'If the land is not in ownership or possession': 'N/A', 'Likely displacement of population': 'Yes,Rohtak', 'Status of Forest(Conservation) Act 1980': 'N/A', 'Status of Clearance under EMP Notification': 'N/A', 'Status of Clearance under CRZ Notification': 'N/A', 'Status of Clearance under Wildlife Act 1972': 'N/A', 'Category of aerodrome proposed': 'Private,Internation', 'Whether project located within 150 Km of an existing civilian airport': 'Yes,IGI Airport', 'Whether exemption from any conditions is sought.': 'None', 'Allowing a greenfield airport within 150 Km of an existing civilian airport.': 'None', 'Exemptions being sought form conditionalities imposed by any of the Central Agencies': 'Yes,Exemption of tax from MHRD', 'Facilitation in obtaining approval/clearance from a Central Agency.': 'None', 'Site of Aerodrome': 'Jewar', 'District of Aerodrome': 'Gautam Budh Nagar', 'State of Aerodrome': 'Uttar Pradesh', 'Implementing Agency': 'Flughafen Zurich AG', 'Whether TechnoEconomic Feasibility Report (TM) has been submitted by the Applicant': 'Done', 'Estimated Total Projec Cost': '29560crore', 'Is any foreign participation envisaged. If yes from which countries': 'Yes,Swizerland', 'Capacity of passenger proposed': '12million', 'Capacity of cargo proposed': '2300tons', 'Number of runways': '6', 'Length of runways': '6000ft', 'Number of taxiways': '15', 'Area of Passenger Terminal': '1', 'Area of Cargo Terminal': '1', 'Area earmarked for city side development.': 'Jewar', 'Passenger related amenities on city side like car parking': 'Parking Slot,1000 car parking slots', 'Total Cost of Land': '20000 cr', 'Cost of other adjunct infrastrcure': '2000cr', 'Cost of Airside assets like Runways etc.': '1500cr', 'Cost of Passenger Terminal': '1000cr', 'Cost of Cargo Terminal and other airside aero facilities': '2500cr', 'Cost of Residential': '1000cr', 'Cost of Commerical-city side': '1000cr', 'Cost of other facilities': '1000cr', 'Equity Capital': '15000cr', 'Term Loan': '10000cr', 'External Commercial Borrowings': 'None', 'Any other source': 'None', 'Total Cost of Financing': 'None', 'Foreign Direct Investment (FDI)': 'None', 'Equity including Foreign Investment': 'None', 'Pattern of share holding in the paidup capital': 'N/A', 'Traffic projections made in the TEFR': '12 million passengers per annum', 'Revenue projections': 'including details of fee etc. to be levied,150cr per anum', 'IRR/NPV estimates based on TEFR': 'N/A', 'Accessibility to site': 'Road', 'Proposed projects to provide connectivity': 'Metro by DMRC'}\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Forms/Aerodrome_and_Site_Clearance_Form.pdf\"\n",
    "output_file_name = core_file_name(file_name)\n",
    "#print(output_file_name)\n",
    "\n",
    "csv_output_file = output_file_name+'.csv'\n",
    "if(file_name[-3:]==\"pdf\"):\n",
    "    extract_pdf(file_name,csv_output_file)\n",
    "    \n",
    "else:\n",
    "    extract_jpg(file_name,csv_output_file)\n",
    "    \n",
    "json_output_file = output_file_name+'.json'    \n",
    "result = csv_json(csv_output_file,json_output_file)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aerodrome_and_Site_Clearance_Form/Aerodrome_and_Site_Clearance_Form.json'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving generated file to specific folder of that name\n",
    "os.mkdir(output_file_name)\n",
    "shutil.move(csv_output_file,output_file_name+'/'+csv_output_file)\n",
    "shutil.move(json_output_file,output_file_name+'/'+json_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
